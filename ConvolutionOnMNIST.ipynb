{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQjHqsmTAVLU"
      },
      "source": [
        "## Improve MNIST with Convolutions\n",
        "\n",
        "In this we will improve Fashion MNIST using Convolution to 99.5% accuracy or more by adding convolutional layer and a MaxPooling 2D layer to the model. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZpztRwBouwYp",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyPLXxJfco_T"
      },
      "source": [
        "## Load the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQqZgAgtco_U",
        "outputId": "f015dcde-4548-42ab-848e-c598f0fde2a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load the data\n",
        "\n",
        "# Get only training set\n",
        "(training_images, training_labels), _ = tf.keras.datasets.mnist.load_data() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOi8mEu0co_U"
      },
      "source": [
        "## Pre-processing the data\n",
        "\n",
        "One important step when dealing with image data is to preprocess the data. During the preprocess step you can apply transformations to the dataset that will be fed into your convolutional neural network.\n",
        "\n",
        "Here you will apply two transformations to the data:\n",
        "- Reshape the data so that it has an extra dimension. The reason for this \n",
        "is that commonly you will use 3-dimensional arrays (without counting the batch dimension) to represent image data. The third dimension represents the color using RGB values. This data might be in black and white format so the third dimension doesn't really add any additional information for the classification process but it is a good practice regardless.\n",
        "\n",
        "\n",
        "- Normalize the pixel values so that these are values between 0 and 1. You can achieve this by dividing every value in the array by the maximum.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "euFmpNgAco_V"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: reshape_and_normalize\n",
        "import numpy\n",
        "def reshape_and_normalize(images):\n",
        "    \n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Reshape the images to add an extra dimension\n",
        "    images = images.reshape(-1,28,28,1)\n",
        "    \n",
        "    # Normalize pixel values\n",
        "    images = images/255.0\n",
        "    \n",
        "    ### END CODE HERE\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdqwI_TXco_V"
      },
      "source": [
        "Test your function with the next cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVXheNDkco_V",
        "outputId": "06693203-c298-47e9-ba88-ba1cc364bcd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum pixel value after normalization: 1.0\n",
            "\n",
            "Shape of training set after reshaping: (60000, 28, 28, 1)\n",
            "\n",
            "Shape of one image after reshaping: (28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "# Reload the images in case you run this cell multiple times\n",
        "(training_images, _), _ = tf.keras.datasets.mnist.load_data() \n",
        "\n",
        "# Apply your function\n",
        "training_images = reshape_and_normalize(training_images)\n",
        "\n",
        "print(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\n",
        "print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n",
        "print(f\"Shape of one image after reshaping: {training_images[0].shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XskwfPM9co_X"
      },
      "source": [
        "## Defining your callback\n",
        "\n",
        "Now complete the callback that will ensure that training will stop after an accuracy of 99.5% is reached:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "X9Pp4tbMco_X"
      },
      "outputs": [],
      "source": [
        "#  CLASS: myCallback\n",
        "\n",
        "# Remember to inherit from the correct class\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "       \n",
        "        def on_epoch_end(self, epoch, logs={}):\n",
        "            if logs.get('accuracy') is not None and logs.get('accuracy') > 0.995:\n",
        "                print(\"\\nReached 99% accuracy so cancelling training!\") \n",
        "                \n",
        "                # Stop training once the below condition is met\n",
        "                self.model.stop_training = True\n",
        "            \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k7-oAnhco_X"
      },
      "source": [
        "## Convolutional Model\n",
        "\n",
        "Finally, complete the `convolutional_model` function below. This function should return your convolutional neural network.\n",
        "\n",
        "**Your model should achieve an accuracy of 99.5% or more before 10 epochs to pass this assignment.**\n",
        "\n",
        "**Hints:**\n",
        "- You can try any architecture for the network but try to keep in mind you don't need a complex one. For instance, only one convolutional layer is needed. \n",
        "\n",
        "- In case you need extra help you can check out an architecture that works pretty well at the end of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "g_VM_Xbico_Y"
      },
      "outputs": [],
      "source": [
        "# FUNCTION: convolutional_model\n",
        "def convolutional_model():\n",
        "  \n",
        "\n",
        "    # Define the model\n",
        "    model = tf.keras.models.Sequential([ \n",
        "      tf.keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(28,28,1)),\n",
        "       tf.keras.layers.MaxPooling2D(2,2) ,\n",
        "     tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "       tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(125,activation='relu'),\n",
        "        tf.keras.layers.Dense(10,activation='softmax')\n",
        "        \n",
        "    ]) \n",
        "\n",
        "\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', \n",
        "                  loss='sparse_categorical_crossentropy', \n",
        "                  metrics=['accuracy']) \n",
        "        \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgPbHchsco_Y",
        "outputId": "3d4ccb6f-5d86-442f-8163-bee7c237f48d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 93s 49ms/step - loss: 0.1235 - accuracy: 0.9624\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 92s 49ms/step - loss: 0.0395 - accuracy: 0.9878\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 91s 49ms/step - loss: 0.0272 - accuracy: 0.9917\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 93s 50ms/step - loss: 0.0190 - accuracy: 0.9939\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9957\n",
            "Reached 99% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 91s 49ms/step - loss: 0.0138 - accuracy: 0.9957\n"
          ]
        }
      ],
      "source": [
        "# Save your untrained model\n",
        "model = convolutional_model()\n",
        "\n",
        "# Instantiate the callback class\n",
        "callbacks = myCallback()\n",
        "\n",
        "# Train your model (this can take up to 5 minutes)\n",
        "history = model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c5IyNMpco_Y"
      },
      "source": [
        "If you see the message that you defined in your callback printed out after less than 10 epochs it means your callback worked as expected. You can also double check by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "Ii-7l11jco_Y",
        "outputId": "a3a8b1a9-59af-4dff-8884-bf174c71811a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your model was trained for 5 epochs\n"
          ]
        }
      ],
      "source": [
        "print(f\"Your model was trained for {len(history.epoch)} epochs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8AeuGLGco_Z"
      },
      "source": [
        "\n",
        "\n",
        "You have successfully implemented a CNN to assist you in the image classification task. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ll5eT3u3eAhc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "ConvolutionOnMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}